{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/So6PBTbRRaNtKuKILFR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poietes5150/SuperCoding/blob/main/pytorch_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igVz7CbbG5an",
        "outputId": "bddf4208-f107-4396-9f1f-77e64743457d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 버전: 2.6.0+cu124\n",
            "CUDA 사용 가능 여부: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능 여부: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Tensor 생성**"
      ],
      "metadata": {
        "id": "iZzi1NPhHiZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor는 PyTorch의 기본 데이터 구조입니다. 아래는 다양한 방법으로 텐서를 생성하는 예시입니다."
      ],
      "metadata": {
        "id": "cMHs0U_fHloS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import X_OK\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 리스트로부터 생성\n",
        "data = [[1,2], [3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"원본 데이터로부터 생성:\\n {x_data}\")\n",
        "print(f\"\\tndim: {x_data.ndim}\")\n",
        "print(f\"\\tshape: {x_data.shape}\")\n",
        "print(f\"\\tsize: {x_data.size()}\")\n",
        "\n",
        "# NumPy (ndarray) 배열로부터 생성\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(f\"NumPy 배열로부터 생성:\\n {x_np}\")\n",
        "\n",
        "# 다른 텐서와 동일한 형태로 생성\n",
        "X_ones = torch.ones_like(x_data)      # 1로 채움\n",
        "print(f\"1로 채운 텐서:\\n {X_ones}\")\n",
        "\n",
        "# 0~1 사이 랜덤\n",
        "X_rand = torch.rand_like(x_data, dtype=torch.float)\n",
        "print(f\"랜덤 텐서:\\n {X_rand}\")\n",
        "\n",
        "# float로 변환\n",
        "x_int = np.arange(10).reshape(5,2)\n",
        "x_float = torch.FloatTensor(x_int)\n",
        "print(f\"float 텐선:\\n {x_float}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IubvQvOHt9I",
        "outputId": "d1de9e8b-1be5-4a90-99ab-4e094af157c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 데이터로부터 생성:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "\tndim: 2\n",
            "\tshape: torch.Size([2, 2])\n",
            "\tsize: torch.Size([2, 2])\n",
            "NumPy 배열로부터 생성:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "1로 채운 텐서:\n",
            " tensor([[1, 1],\n",
            "        [1, 1]])\n",
            "랜덤 텐서:\n",
            " tensor([[0.5157, 0.4292],\n",
            "        [0.5148, 0.5970]])\n",
            "float 텐선:\n",
            " tensor([[0., 1.],\n",
            "        [2., 3.],\n",
            "        [4., 5.],\n",
            "        [6., 7.],\n",
            "        [8., 9.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 개발 환경에서 cuda 사용이 가능한 경우, tensor 를 cuda 버전으로 변경\n",
        "x_data.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjxfr6CCNLDN",
        "outputId": "8b51b5e8-9f59-4289-8ddd-10b60a38a210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 개발 환경에서 cuda 사용이 가능한 경우, tensor 를 cuda 버전으로 변경\n",
        "print(x_data.device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    # x_data_cuda = x_data.cuda()\n",
        "    x_data_cuda = x_data.to(\"cuda\")\n",
        "x_data_cuda.device\n",
        "print(x_data_cuda.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Or9aS0oNXNQ",
        "outputId": "2d5cd82e-a309-4434-e473-f9998887b408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensor와 NumPy 간 변환**"
      ],
      "metadata": {
        "id": "ANboE0fwN5AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import X_OK\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 텐서를 NumPyㄹ 배열로 변환\n",
        "tensor = torch.ones(3,3)\n",
        "print(f\"텐서:\\n {tensor}\")\n",
        "np_tensor = tensor.numpy()\n",
        "print(f\"텐서를 넘파이 배열러 변환:\\n {np_tensor}, {type(np_tensor)}\")\n",
        "\n",
        "# NumPy 배열을 텐서로 변환\n",
        "tensor_from_np = torch.from_numpy(np_tensor)\n",
        "print(f\"넘파이 배열을 텐서로 변환:\\n {tensor_from_np}, {type(tensor_from_np)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jNs_kV5OKI1",
        "outputId": "4c5bd020-53a2-4180-dbda-2fde4a2c79a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텐서:\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "텐서를 넘파이 배열러 변환:\n",
            " [[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]], <class 'numpy.ndarray'>\n",
            "넘파이 배열을 텐서로 변환:\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]]), <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NumPy와 유사한 operations**"
      ],
      "metadata": {
        "id": "X_7UwdTYPAzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "data = [[4,5,6],[50,20,10],[-2,8,22]]\n",
        "x_data = torch.tensor(data)\n",
        "print(x_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FJDxEBvPFT-",
        "outputId": "62da1a96-09b3-49c0-8dae-6f1ce5b7a034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4,  5,  6],\n",
            "        [50, 20, 10],\n",
            "        [-2,  8, 22]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor를 인덱싱\n",
        "x_data[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoRrvqZOPUS3",
        "outputId": "9112c52d-64ba-455b-ba6c-6e96c0d93565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[50, 20, 10],\n",
              "        [-2,  8, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data[:2, 1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdthpph0PYcr",
        "outputId": "09325617-6a8d-4f61-d117-311c9f0aca70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5,  6],\n",
              "        [20, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_np = x_data.numpy()\n",
        "x_data_np[:2, 1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa1-VoWrPhYc",
        "outputId": "b04eb2b8-c671-48d3-c12c-0344d0166f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  6],\n",
              "       [20, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor를 1차원의 vector로\n",
        "x_data.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GOV-5LQPvsr",
        "outputId": "ae18a476-34df-4559-9761-c1c6693784c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4,  5,  6, 50, 20, 10, -2,  8, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_data shape과 동일한 크기로 원소 1을 같는 tensor 생성\n",
        "torch.ones_like(x_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5vFxhGOP0jv",
        "outputId": "3776ce89-b5e9-4777-ef6d-52416f01ba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1],\n",
              "        [1, 1, 1],\n",
              "        [1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Tensor 속성과 연산**"
      ],
      "metadata": {
        "id": "yV24yzAnP-bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "tensor = torch.rand(3,4)\n",
        "print(f\"ndim (차원): {tensor.ndim}\")\n",
        "print(f\"size (크기): {tensor.size()}\")\n",
        "print(f\"shape (모양): {tensor.shape}\")\n",
        "print(f\"dtype (자료형): {tensor.dtype}\")\n",
        "print(f\"device (장치): {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL1L3U2pQAuW",
        "outputId": "3c85fa09-b100-4238-97a6-0e39f844fcb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndim (차원): 2\n",
            "size (크기): torch.Size([3, 4])\n",
            "shape (모양): torch.Size([3, 4])\n",
            "dtype (자료형): torch.float32\n",
            "device (장치): cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서 조작 예시"
      ],
      "metadata": {
        "id": "y4IyPkTyQf7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   view() = contigous (연속 메모리) 필요, 일반적으로 복사 안함, 속도 빠름, 오류 발생 가능\n",
        "*   reshape() - 연속메모리 필요 없음 (메모리 자동처리), 필요시 복사, 메모리 자동처리 되므로 오류 적음, 복사 발생시 느릴 수 있음\n",
        "\n"
      ],
      "metadata": {
        "id": "7byQWeq5Qk4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인자로 받은 size의 random tensor를 생성\n",
        "tensor_ex = torch.rand(size=(2,3,2))\n",
        "print(tensor_ex)\n",
        "\n",
        "# tensor가 contigous한 경우, 인자로 받은 사이즈에 맞춰 tensor의 사이즈를 변경\n",
        "# contigous (연속 메모리) 필요, 일반적으로 복사 안함, 속도 빠름, 오류 발생 가능\n",
        "tensor_ex.view([-1, 6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu9TE4bbQ4oC",
        "outputId": "32c2b8c7-fbae-40b5-d496-49f26fe6d856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.7261, 0.5943],\n",
            "         [0.6313, 0.4893],\n",
            "         [0.1472, 0.1933]],\n",
            "\n",
            "        [[0.2466, 0.1100],\n",
            "         [0.6276, 0.9524],\n",
            "         [0.2300, 0.0473]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7261, 0.5943, 0.6313, 0.4893, 0.1472, 0.1933],\n",
              "        [0.2466, 0.1100, 0.6276, 0.9524, 0.2300, 0.0473]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor의 contigous 상태에 관계없이, tensor의 사이즈를 변경\n",
        "# 연속메모리 필요 없음 (메모리 자동처리), 필요시 복사, 메모리 자동처리 되므로 오류 적음, 복사 발생시 느릴 수 있음\n",
        "tensor_ex.reshape([-1, 6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d8mvxYcRTdt",
        "outputId": "ef25ad24-9b3c-43de-8621-0243d564ef1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7261, 0.5943, 0.6313, 0.4893, 0.1472, 0.1933],\n",
              "        [0.2466, 0.1100, 0.6276, 0.9524, 0.2300, 0.0473]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 1. 원본 텐서 생성\n",
        "x = torch.randn(2, 3)\n",
        "print(f\"원본 x:\\n{x}\")\n",
        "# 2. 전치(transpose) -> 메모리가 연속되지 않음\n",
        "x_t = x.t()   # shape: (3,2)\n",
        "print(f\"\\n전치 x_t:\\n{x_t}\")\n",
        "# 3. view 시도 -> 실패(RuntimeError 발생)\n",
        "try:\n",
        "  x_view = x_t.view(6)\n",
        "except RuntimeError as e:\n",
        "  print(f\"\\n.view() 에러 발생: {e}\")\n",
        "# 4. reshape 시도 -> 성공 (필요하면 복사)\n",
        "x_reshape = x_t.reshape(6)\n",
        "print(f\"\\n.reshape() 성공:\\n {x_reshape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxKdSDn_Ric1",
        "outputId": "34f02832-a41e-4cff-9e74-b8c083069f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 x:\n",
            "tensor([[-1.7167,  0.5024,  0.6261],\n",
            "        [-0.9967, -0.0513,  2.0880]])\n",
            "\n",
            "전치 x_t:\n",
            "tensor([[-1.7167, -0.9967],\n",
            "        [ 0.5024, -0.0513],\n",
            "        [ 0.6261,  2.0880]])\n",
            "\n",
            ".view() 에러 발생: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
            "\n",
            ".reshape() 성공:\n",
            " tensor([-1.7167, -0.9967,  0.5024, -0.0513,  0.6261,  2.0880])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원소 0을 같는 tensor를 생성하고, 사이즈를 변경 후, 값을 변경\n",
        "# view와 reshape 메서드 간 a, b의 값을 확인해보자\n",
        "# 메모리가 복사를 안했으므로 b도 같이 변함\n",
        "a = torch.zeros(3,2)\n",
        "b = a.view(6)\n",
        "a.fill_(1)\n",
        "\n",
        "print(f\"a:\\n {a}\")\n",
        "print(f\"b:\\n {b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP3IsJv1Ss32",
        "outputId": "4ddffaa6-65ac-4f40-ff2f-38492989b0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "b:\n",
            " tensor([1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원소 0을 같는 tensor를 생성하고, 사이즈를 변경 후, 값을 변경\n",
        "# 메모리가 복사되었으므로 b는 안 변함\n",
        "a = torch.zeros(3,2)\n",
        "b = a.t().reshape(6)\n",
        "a.fill_(1)\n",
        "\n",
        "print(f\"a:\\n {a}\")\n",
        "print(f\"b:\\n {b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6tCpS2OTC4t",
        "outputId": "8ec9a720-17fe-4ca5-abe0-dc34f88f684c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            " tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "b:\n",
            " tensor([0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   squeez(), unsqueeze()\n",
        "\n"
      ],
      "metadata": {
        "id": "XfC5ogOBTrMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서를 생성한 후, 크기 1의 차원을 같는 dimension을 squeeze\n",
        "# size = (1) => 열\n",
        "# size = (1,2) => 행, 열\n",
        "# size = (2,1,2) => 깊이, 행, 열\n",
        "# 앞으로 하나씩 붙는다 => axis\n",
        "tensor_ex = torch.rand(size=(2,1,2))\n",
        "print(tensor_ex)\n",
        "print(tensor_ex.shape)\n",
        "\n",
        "tensor_ex_squeezed = tensor_ex.squeeze()\n",
        "print(tensor_ex_squeezed)\n",
        "print(tensor_ex_squeezed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjl20sslTvtW",
        "outputId": "02d7eeb8-772b-4299-f8ef-815f64cdd489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.6423, 0.7641]],\n",
            "\n",
            "        [[0.2334, 0.9937]]])\n",
            "torch.Size([2, 1, 2])\n",
            "tensor([[0.6423, 0.7641],\n",
            "        [0.2334, 0.9937]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 차원에 축을 생성\n",
        "tensor_ex = torch.rand(size=(2,2))\n",
        "print(tensor_ex)\n",
        "print(tensor_ex.unsqueeze(0).shape)\n",
        "print(tensor_ex.unsqueeze(0))\n",
        "print(tensor_ex.unsqueeze(1).shape)\n",
        "print(tensor_ex.unsqueeze(1))\n",
        "print(tensor_ex.unsqueeze(2).shape)\n",
        "print(tensor_ex.unsqueeze(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-exTwpWJVo-k",
        "outputId": "bbc81915-5be7-4360-f31a-52a1f11e7491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1668, 0.1248],\n",
            "        [0.7293, 0.5722]])\n",
            "torch.Size([1, 2, 2])\n",
            "tensor([[[0.1668, 0.1248],\n",
            "         [0.7293, 0.5722]]])\n",
            "torch.Size([2, 1, 2])\n",
            "tensor([[[0.1668, 0.1248]],\n",
            "\n",
            "        [[0.7293, 0.5722]]])\n",
            "torch.Size([2, 2, 1])\n",
            "tensor([[[0.1668],\n",
            "         [0.1248]],\n",
            "\n",
            "        [[0.7293],\n",
            "         [0.5722]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = torch.ones(2,1,2)\n",
        "print(test1)\n",
        "test2 = torch.ones(size=(2,3))\n",
        "print(test2)\n",
        "test3 = torch.ones(size=(2,1,2))\n",
        "print(test3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITJCr_cbXnjD",
        "outputId": "479bd633-d5cf-4020-bfa3-4614c88bb0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1.]],\n",
            "\n",
            "        [[1., 1.]]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[[1., 1.]],\n",
            "\n",
            "        [[1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서 연산 예시"
      ],
      "metadata": {
        "id": "6UZ7bmBfTK3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[10,20],[30,40]])\n",
        "c = torch.tensor([1,2,3])\n",
        "d = torch.tensor([4,5,6])\n",
        "\n",
        "print(f\"덧셈: \\n {a+b}\")\n",
        "print(f\"요소별(성분) 곱셈: \\n {a*b}\")\n",
        "print(f\"행렬곱(matmul): \\n {torch.matmul(a, b)}\")\n",
        "print(f\"행렬곱(mm, 2D): \\n {torch.mm(a, b)}\") # 행렬곱 2D 에서만 가능\n",
        "print(f\"행렬곱(dot, 1D): \\n {torch.dot(c, d)}\") # 행렬곱 1D 에서만 가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbf9McJ0TJ8d",
        "outputId": "139402ca-9580-43a5-fa32-b18885bffb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "덧셈: \n",
            " tensor([[11, 22],\n",
            "        [33, 44]])\n",
            "요소별(성분) 곱셈: \n",
            " tensor([[ 10,  40],\n",
            "        [ 90, 160]])\n",
            "행렬곱(matmul): \n",
            " tensor([[ 70, 100],\n",
            "        [150, 220]])\n",
            "행렬곱(mm, 2D): \n",
            " tensor([[ 70, 100],\n",
            "        [150, 220]])\n",
            "행렬곱(dot, 2D): \n",
            " 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# broad casting\n",
        "print(a+10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw0ZJzEyUlmN",
        "outputId": "c05af9c8-8469-4525-a892-c5ff3d31ed58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11, 12],\n",
            "        [13, 14]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# broad casting이 지원되어 행렬 곱 연산이 가능\n",
        "a = torch.rand(5,2,3)\n",
        "print(a.shape)\n",
        "b = torch.rand(3,4)\n",
        "print(b.shape)\n",
        "a.matmul(b).shape\n",
        "\n",
        "# b가 5번 복제된 것 처럼 동작"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26InEluDUrBq",
        "outputId": "5344081a-6174-4891-a8fd-7ea9b9c570e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 2, 3])\n",
            "torch.Size([3, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1,2],[3,4],[5,6]]) # shape: (3, 2)\n",
        "b = torch.tensor([1,0])               # shape: (2,)\n",
        "\n",
        "# (3, 2) @ (2,) -> (3,) 결과: 각행 벡터와 b의 내적\n",
        "print(A)\n",
        "print(b)\n",
        "out = torch.matmul(A, b)  # broadcasting\n",
        "print(out)  # tensor([ 5, 11, 17 ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrOOMiUzVHMq",
        "outputId": "0bf4aef7-807c-4587-8eb4-160f403ea003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([1, 0])\n",
            "tensor([1, 3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. CUDA(GPU) 사용하기**"
      ],
      "metadata": {
        "id": "Fgz8c67sV0z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "tensor = torch.rand(3, 4)\n",
        "print(f\"현재 사용중인 장치: {tensor.device}\")\n",
        "\n",
        "# 현재 개발 환경에서 cuda 사용이 가능한 경우, tensor를 cuda 버전으로 변경\n",
        "if torch.cuda.is_available():\n",
        "  tensor_cuda = tensor.to('cuda')\n",
        "  print(f\"GPU로 이동한 텐서:\\n{tensor_cuda}\")\n",
        "\n",
        "# 다시 CPU로 이동\n",
        "tensor_cpu = tensor.to(\"cpu\")\n",
        "print(f\"다시 CPU로 이동한 텐서:\\n{tensor_cpu}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB7OMjJsV6O7",
        "outputId": "d71961c7-21cd-4d7e-8148-7369e2e9ccb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 사용중인 장치: cpu\n",
            "GPU로 이동한 텐서:\n",
            "tensor([[0.3733, 0.8158, 0.3282, 0.1865],\n",
            "        [0.6482, 0.7045, 0.2159, 0.0085],\n",
            "        [0.7170, 0.7988, 0.3959, 0.6191]], device='cuda:0')\n",
            "다시 CPU로 이동한 텐서:\n",
            "tensor([[0.3733, 0.8158, 0.3282, 0.1865],\n",
            "        [0.6482, 0.7045, 0.2159, 0.0085],\n",
            "        [0.7170, 0.7988, 0.3959, 0.6191]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 머신러닝/딥러닝을 위한 tensor 연산"
      ],
      "metadata": {
        "id": "Jpz5UFMnYySI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "tensor = torch.FloatTensor([0.6, 0.2, 0.1])\n",
        "# 생성한 tensor에서 softmax 함수를 계산\n",
        "h_tensor = torch.nn.functional.softmax(tensor, dim=0)\n",
        "print(h_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w24T9iAtY3Al",
        "outputId": "2dff3e8d-9d28-4149-c571-256fa7b69333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4392, 0.2944, 0.2664])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F # 이런식으로 많이 사용\n",
        "\n",
        "tensor = torch.FloatTensor([0.6, 0.2, 0.1])\n",
        "# 생성한 tensor에서 softmax 함수를 계산\n",
        "h_tensor = F.softmax(tensor, dim=0)\n",
        "print(h_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5EFxp5GZJqz",
        "outputId": "6d0d8127-b360-47dc-8558-87ce6afcedff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4392, 0.2944, 0.2664])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 텐서 (10행 5열)\n",
        "y = torch.randint(5, (10, 5))\n",
        "print(f\"y:\\n{y}\")\n",
        "\n",
        "# 각 행의 argmax (최대값의 인덱스)\n",
        "y_label = y.argmax(dim=1)\n",
        "print(f\"argmax indices:\\n{y_label}\")\n",
        "\n",
        "# 최대값 자체를 구하려면\n",
        "y_max = y.max(dim=1)\n",
        "print(f\"max values:\\n{y_max}\")\n",
        "\n",
        "# y_label 이용하는 방법 1: torch.gather 사용 (추천!)\n",
        "y_max = torch.gather(y, 1, y_label.unsqueeze(1)).squeeze(1)\n",
        "print(f\"max values:\\n{y_max}\")\n",
        "\n",
        "# y_label 방법 2: python 리스트 스타일 (느림!)\n",
        "y_max = torch.tensor([row[idx] for row, idx in zip(y, y_label)])\n",
        "print(f\"max values:\\n{y_max}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGzH-9oiZWhO",
        "outputId": "580078a2-ede6-421e-9d80-a8e6b3947520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y:\n",
            "tensor([[1, 4, 2, 1, 2],\n",
            "        [1, 1, 0, 2, 0],\n",
            "        [3, 0, 4, 1, 2],\n",
            "        [2, 4, 0, 4, 3],\n",
            "        [4, 2, 1, 4, 3],\n",
            "        [3, 0, 3, 2, 1],\n",
            "        [2, 0, 1, 1, 0],\n",
            "        [2, 3, 1, 1, 2],\n",
            "        [0, 4, 4, 3, 2],\n",
            "        [4, 0, 1, 1, 0]])\n",
            "argmax indices:\n",
            "tensor([1, 3, 2, 1, 0, 0, 0, 1, 1, 0])\n",
            "max values:\n",
            "torch.return_types.max(\n",
            "values=tensor([4, 2, 4, 4, 4, 3, 2, 3, 4, 4]),\n",
            "indices=tensor([1, 3, 2, 1, 0, 0, 0, 1, 1, 0]))\n",
            "max values:\n",
            "tensor([4, 2, 4, 4, 4, 3, 2, 3, 4, 4])\n",
            "max values:\n",
            "tensor([4, 2, 4, 4, 4, 3, 2, 3, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot 인코딩으로 변환합니다.\n",
        "torch.nn.functional.one_hot(y_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMOcQqJrar34",
        "outputId": "ae5edf0f-1c69-4918-aeab-0a0a7fbae7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 0, 0],\n",
              "        [0, 0, 0, 1],\n",
              "        [0, 0, 1, 0],\n",
              "        [0, 1, 0, 0],\n",
              "        [1, 0, 0, 0],\n",
              "        [1, 0, 0, 0],\n",
              "        [1, 0, 0, 0],\n",
              "        [0, 1, 0, 0],\n",
              "        [0, 1, 0, 0],\n",
              "        [1, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# cartesian product를 수행합니다.\n",
        "a = [1, 2, 3]\n",
        "b = [10, 20]\n",
        "list(itertools.product(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgyx8fTkbFRL",
        "outputId": "e337cbf1-1bb3-43b4-b1b4-833b93643ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 10), (1, 20), (2, 10), (2, 20), (3, 10), (3, 20)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 에서 지원하는 메서드를 통해 cartesian product를 수행합니다.\n",
        "a = [1, 2, 3]\n",
        "b = [10, 20]\n",
        "\n",
        "tensor_a = torch.tensor(a)\n",
        "tensor_b = torch.tensor(b)\n",
        "torch.cartesian_prod(tensor_a, tensor_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO_Oyb4gbUbo",
        "outputId": "dc290333-95ac-4094-b5b0-70cab72cf0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, 10],\n",
              "        [ 1, 20],\n",
              "        [ 2, 10],\n",
              "        [ 2, 20],\n",
              "        [ 3, 10],\n",
              "        [ 3, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 연습 문제 & 정답\n",
        "\n",
        "**Q1.** shape이 (3,3)이고 값이 모두 7인 텐서를 만들어 보세요.\n",
        "\n",
        "**Q2.** 랜덤 텐서 두 개를 생성하고 덧셈과 곱셈 결과를 출력해 보세요.\n",
        "\n",
        "**Q3.** torch.matmul()을 이용해 2x3, 3x2 행렬의 곱을 계산해 보세요.\n",
        "\n",
        "**Q4.** 아래와 같이 텐서를 생성하고 CUDA를 지원하면 GPU로 이동해 보세요.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "tensor = torch.rand(3, 4)\n",
        "tensor = tensor.to(\"cpu\")\n",
        "print(f\"현재 device: {tensor.device}\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PrEn1O83bpgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1. shape이 (3,3)이고 값이 모두 7인 텐서를 만들어 보세요.\n",
        "tensor_q1 = torch.full((3, 3), 7)\n",
        "print(tensor_q1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEvvFzRQbs6R",
        "outputId": "6ee166ab-8105-4431-ab51-ca4805aa5b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[7, 7, 7],\n",
            "        [7, 7, 7],\n",
            "        [7, 7, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. 랜덤 텐서 두 개를 생성하고 덧셈과 곱셈 결과를 출력해 보세요.\n",
        "tensor_q2_1 = torch.rand(3, 4)\n",
        "tensor_q2_2 = torch.rand(3, 4)\n",
        "print(tensor_q2_1 * tensor_q2_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6JAKavHdDEj",
        "outputId": "dbb5afeb-53c2-4b79-bab8-6b78e402ad84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2538, 0.3025, 0.0300, 0.0541],\n",
            "        [0.4008, 0.0668, 0.0791, 0.3617],\n",
            "        [0.0794, 0.1034, 0.0719, 0.1044]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. torch.matmul()을 이용해 2x3, 3x2 행렬의 곱을 계산해 보세요.\n",
        "tensor_q3_1 = torch.rand(2, 3)\n",
        "tensor_q3_2 = torch.rand(3, 2)\n",
        "print(torch.matmul(tensor_q3_1, tensor_q3_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOFpf7U1dEUO",
        "outputId": "0e89708b-be17-40e4-fadb-769336bd0d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9792, 0.3069],\n",
            "        [1.4881, 0.4273]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. 아래와 같이 텐서를 생성하고 CUDA를 지원하면 GPU로 이동해 보세요.\n",
        "tensor = torch.rand(3, 4)\n",
        "tensor = tensor.to(\"cpu\")\n",
        "print(f\"현재 device: {tensor.device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to(\"cuda\")\n",
        "  print(f\"현재 device: {tensor.device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICSEEQaydHNf",
        "outputId": "6e682308-0b76-4125-919c-c0c3d670cb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 device: cpu\n",
            "현재 device: cuda:0\n"
          ]
        }
      ]
    }
  ]
}